
#+STARTUP: content
#+STARTUP: overview
#+STARTUP: indent
#+STARTUP: latexpreview
#+TITLE: Notes on implementing the PCAD Digital Twin with SimGrid.
#+AUTHOR: Rayan Raddatz de Matos


* Idea
The idea is to create a "replica" of the PCAD in [[https://simgrid.org/doc/latest/index.html][SimGrid]] using the C++ interface

* Work
** Makefile
#+begin_src makefile :tangle Makefile
CPPC=g++
CPPFLAGS=-shared -Wall -Werror -fPIC
LIBS=simgrid

.PHONY: clean platform

export PKG_CONFIG_PATH := /opt/simgrid/lib/pkgconfig:$(PKG_CONFIG_PATH) # export installation path to simgrid

pcad:
	g++ -shared -fPIC -o pcad.so create-pcad.cpp `pkg-config --cflags --libs $(LIBS)`

base:
	g++ -shared -fPIC -o libgriffon_platform.so base.cpp `pkg-config --cflags --libs $(LIBS)`

clean:
	rm -f *.so
#+end_src

** Base example (from simgrid docs)
#+begin_src C++ :tangle base.cpp :results output :exports both :main no
/* Copyright (c) 2006-2025. The SimGrid Team. All rights reserved.          */

/* This program is free software; you can redistribute it and/or modify it
 * under the terms of the license (GNU LGPL) which comes with this package. */

#include <numeric>
#include <simgrid/s4u.hpp>
namespace sg4 = simgrid::s4u;

/**
 * @brief Create a new cabinet
 *
 * This function creates the cabinet, adding the hosts and links properly.
 * See figure below for more details of each cabinet
 *
 * @param root Root netzone
 * @param name Cabinet name
 * @param radicals IDs of nodes inside the cabinet
 * @return netzone the created netzone
 */
static sg4::NetZone* create_cabinet(sg4::NetZone* root, const std::string& name, const std::vector<int>& radicals)
{
  auto* cluster      = root->add_netzone_star(name);
  std::string prefix = "griffon-";
  std::string suffix = ".nancy.grid5000.fr";

  /* create the backbone link */
  const sg4::Link* l_bb = cluster->add_link("backbone-" + name, "1.25GBps");
  sg4::LinkInRoute backbone(l_bb);

  /* create all hosts and connect them to outside world */
  for (const auto& id : radicals) {
    std::string hostname = prefix + std::to_string(id) + suffix;
    /* create host */
    const sg4::Host* host = cluster->add_host(hostname, "286.087kf");
    /* create UP/DOWN link */
    const sg4::Link* link = cluster->add_split_duplex_link(hostname, "125MBps")->set_latency("24us");

    /* add link and backbone for communications from the host */
    cluster->add_route(host, nullptr, {{link, sg4::LinkInRoute::Direction::UP}, backbone}, true);
  }

  /* create gateway */

  cluster->set_gateway(cluster->add_router(prefix + name + "-router" + suffix));

  cluster->seal();
  return cluster;
}

/** @brief Programmatic version of griffon.xml */
extern "C" void load_platform(sg4::Engine& e);
void load_platform(sg4::Engine& e)
{
  /**
   * C++ version of griffon.xml
   * Old Grid5000 cluster (not available anymore): 3 cabinets containing homogeneous nodes connected through a backbone
   *                                  1.25GBps shared link
   *                          ___________________________________
   *          1              /                |                  \
   *                        /                 |                   \
   *                       /                  |                    \
   *     ________________ /             ______|__________           \_________________
   *     |               |              |               |            |               |
   *     | cab1 router   |              | cab2 router   |            | cab3 router   |
   *     |_______________|              |_______________|            |_______________|
   *     ++++++++++++++++               ++++++++++++++++             ++++++++++++++++++  <-- 1.25 backbone
   *     / /   | |    \ \              / /    | |    \ \             / /     | |     \ \
   *    / /    | |     \ \            / /     | |     \ \           / /      | |      \ \ <-- 125Mbps links
   *   / /     | |      \ \          / /      | |      \ \         / /       | |       \ \
   * host1     ...      hostN      host1      ...      hostM      host1      ...       hostQ
   */

  auto* root = e.get_netzone_root()->add_netzone_star("AS_griffon");

  /* create top link */
  const sg4::Link* l_bb = root->add_link("backbone", "1.25GBps")->set_latency("24us")->seal();
  sg4::LinkInRoute backbone{l_bb};

  /* create cabinet1 */
  std::vector<int> rad(32);
  std::iota(rad.begin(), rad.end(), 1); // 1-29,58,59,60
  rad[rad.size() - 1]  = 60;
  rad[rad.size() - 2]  = 59;
  rad[rad.size() - 3]  = 58;
  const sg4::NetZone* cab_zone = create_cabinet(root, "cabinet1", rad);
  root->add_route(cab_zone, nullptr, {backbone});

  /* create cabinet2 */
  rad.resize(28);
  std::iota(rad.begin(), rad.end(), 30); // 30-57
  cab_zone = create_cabinet(root, "cabinet2", rad);
  root->add_route(cab_zone, nullptr, {backbone});

  /* create cabinet3 */
  rad.resize(32);
  std::iota(rad.begin(), rad.end(), 61); // 61-92
  cab_zone = create_cabinet(root, "cabinet3", rad);
  root->add_route(cab_zone, nullptr, {backbone});

  root->seal();
}
#+end_src

** Create PCAD (the currently exact version)
:PROPERTIES:
:header-args: :tangle create-pcad.cpp :main no
:END:

This currently has rack2 cei and draco and rack4 tupi and poti (not
fully configurated). Based on the simgrid example.

*** Libraries and namespace
#+begin_src C++ :results output :exports both
#include <numeric>
#include <simgrid/s4u.hpp>

namespace sg4 = simgrid::s4u;
#+end_src

*** Structs
#+begin_src C++ :results output :exports both
typedef struct partition {
    std::string name;
    std::string speed;
    std::string bw;
    std::string lat;
    int count;
} partition_t;
#+end_src
*** Generic function to create one partition
#+begin_src C++ :results output :exports both

/**
 * @brief Create a partition with N machines
 *
 * This function creates the any partition, adding the hosts and links properly.
 *
 * @param root Root netzone
 * @param switch_fatpipe Switch link for the rack to model the connection
 * @param partition Information about the hosts in the partition
 */
void create_partition(sg4::NetZone* rack,
                      sg4::Link* switch_fatpipe,
		      partition_t partition)
{
  for (int id = 1; id <= partition.count; id++) {
    std::string hostname = partition.name + std::to_string(id);

    auto* host = rack->add_host(hostname, partition.speed)->seal();
    auto* node_cable = rack->add_link(hostname + "_cable", partition.bw)->set_latency(partition.lat)->seal();

    // Looks like StarZone automatically calculates the path to the netzone gateway when the second argument is a nullptr
    rack->add_route(host,
                    nullptr,
                    std::vector<const sg4::Link*>{node_cable, switch_fatpipe});
  }
}

#+end_src
*** Generic function to create one rack
#+begin_src C++ :results output :exports both
/**
 * @brief Create a rack with N partitions
 *
 * This function creates the a rack, adding the internal partitions linked correctly.
 *
 * @param root Root netzone
 * @param rack_name Rack name
 * @param partitions Vector with the partitions information
 */
sg4::NetZone *create_rack(sg4::NetZone *root, std::string rack_name,
			  std::string switch_capacity, std::string switch_latency,
                          std::vector<partition_t> partitions)
    {

      auto* rack_zone = root->add_netzone_star(rack_name);
      auto* rack_router = rack_zone->add_router(rack_name + "_router");
      rack_zone->set_gateway(rack_router); // rack gateaway

      // Create Fatpipe to simulat the switch
      auto* rack_switch_fatpipe = rack_zone->add_link(rack_name + "_fatpipe", switch_capacity)
	->set_latency(switch_latency)
	->set_sharing_policy(sg4::Link::SharingPolicy::FATPIPE)
	->seal();

      // Nodes partitions (nodes)
      for(const auto& partition : partitions){
	create_partition(rack_zone, rack_switch_fatpipe, partition);

      }

      rack_zone->seal();
      return rack_zone;
}
#+end_src

*** MAIN: Creating two racks with some partitions (cei, draco, poti, tupi)
#+begin_src C++ :results output :exports both

/** @brief Programmatic version of PCAD */
extern "C" void load_platform(sg4::Engine& e);
void load_platform(sg4::Engine& e)
{
  auto* root = e.get_netzone_root();

  // =-=-=-=-=-=-=-=-=-=-=-= RACK 2 =-=-=-=-=-=-=-=-=-=-=-=
  partition_t cei = {"cei", "100kf", "1Gbps", "50us", 6};
  partition_t draco = {"draco", "50kf", "1Gbps", "50us", 6};
  std::vector<partition_t> rack2_partitions = {cei, draco};

  sg4::NetZone *rack2_zone = create_rack(root, "rack2", "10Gbps", "100ns", rack2_partitions);

  // =-=-=-=-=-=-=-=-=-=-=-= RACK 4 =-=-=-=-=-=-=-=-=-=-=-=
  partition_t tupi = {"tupi", "500kf", "1Gbps", "50us", 6};
  partition_t poti = {"poti", "400kf", "1Gbps", "50us", 6};
  std::vector<partition_t> rack4_partitions = {poti, tupi};

  sg4::NetZone *rack4_zone = create_rack(root, "rack4", "10Gbps", "100ns", rack4_partitions);


  // =-=-=-=-=-=-=-=-=-=-=-= CONNECTION BETWEEN THE RACKS (switchs) =-=-=-=-=-=-=-=-=-=-=-=
  std::string  inter_switch_bw = "10Gbps";
  std::string inter_switch_lat = "50us";

  auto* rack_link = root->add_link("r2_to_r4_cable", inter_switch_bw)
    ->set_latency(inter_switch_lat)
    ->seal();

  // connect the zones
  root->add_route(rack2_zone, rack4_zone, {rack_link});

  root->seal();
}
#+end_src

* Journal
** 2025-11-06
[11:32:57; 06.11.2025]: I will use the base example of the site
(https://simgrid.org/doc/latest/Platform_cpp.html#example) to start.

[11:41:05; 06.11.2025]: The references will stay in a separated
directory.

#+begin_src shell :results output :exports both
ls references
#+end_src

#+RESULTS:
: smpi_article.pdf

** 2025-12-05: SimGrid Install From Source

[08:40:25; 05.12.2025]: The two important points are the creation of
the interface and also the calibration.

[08:45:38; 05.12.2025]: I will start by reading and getting used to
the platform. I also want to start using the examples to see what path
should I follow.

[09:01:00; 05.12.2025]: To calibrate or validate I must first have a
functional (even though small) cluster. I will try to start with a toy
example and scale it to create the CEI partition.

CEI HARDWARE:
| name     | partition | processor                                                        | memory     | accelerator | disk                      | motherboard       |
|----------+-----------+------------------------------------------------------------------+------------+-------------+---------------------------+-------------------|
| cei[1-6] | cei       | 2 x Intel(R) Xeon(R) Silver 4116, 2.10 GHz, 48 threads, 24 cores | 96 GB DDR4 | --          | 21.8 TB HDD, 894.3 GB SSD | Supermicro X11DPU |

They are connected by a 10G Internet Switch.

[09:14:52; 05.12.2025]: I am compiling the simgrid examples to use as
base.

[09:45:13; 05.12.2025]: I think I can modulate to create the
partitions (one function for each partition) and after joint
everything to create the PCAD.

[09:46:51; 05.12.2025]: My debian current MPI version don't have a
fully updated simgrid version. I will probably download from source then.

[10:07:06; 05.12.2025]: Since Lucas said they are shifting toward Nix,
I will probably download the Nix SimGrid Version.

[11:10:48; 05.12.2025]: I made a break to go to super market. I
installed the simgrid from source (git version 4.1.1) and installed at
/opt/simgrid. To compile with this version, i need to change the dkpg
path env variable:

#+begin_src shell :results output :exports both
export PKG_CONFIG_PATH=/opt/simgrid/lib/pkgconfig:$PKG_CONFIG_PATH
#+end_src

and then compile:

#+begin_src shell :results output :exports both
g++ -shared -fPIC -o libgriffon_platform.so base.cpp $(pkg-config --cflags --libs simgrid)
#+end_src

This will create a library to my platform.

** 2025-12-09: Arthur TCC

[10:49:45; 09.12.2025]: TCC do Arthur
[10:49:51; 09.12.2025]: Como é a comunicação no pcad?

Nó -> uma máquina (ex.: cei1)

[11:35:42; 09.12.2025]: SimGrid escala bem

** 2025-12-11: Proxy Apps Working and Topology

[07:23:42; 11.12.2025]: Arrived at the lab, today my plan is to start
designing the cei nodes. I also want to read the two articles cited in
the IC propose.

[07:30:47; 11.12.2025]: Important pages about calibration:
https://simgrid.org/doc/latest/Calibrating_the_models.html#mpi-network-calibration
https://framagit.org/simgrid/platform-calibration/

[07:33:11; 11.12.2025]: [[file:network_topology.pdf]]

If i get it correctly. the topology is as follow:


#+begin_src txt
                             ___________________________________________________________________
                            /                |                              |                   \
                           /                 |                              |                    \  <---- Switch speed connection to other racks
                          /                  |                              |                     \
        ________________ /             ______|__________            ________|________              \_________________
        |               |              |               |            |               |               |               |
        | rack 1 switch |              | rack 2 switch |            | rack 3 switch |               | rack 4 switch | <-- Fatpipe with high capacity and low latency
        |_______________|              |_______________|            |_______________|               |_______________|
        ++++++++++++++++               ++++++++++++++++             ++++++++++++++++++              ++++++++++++++++++
        / /   | |    \ \              / /    | |    \ \             / /     | |     \ \             / /     | |     \ \
       / /    | |     \ \            / /     | |     \ \           / /      | |      \ \           / /      | |      \ \ <-- Switch Speed connection between nodes
      / /     | |      \ \          / /      | |      \ \         / /       | |       \ \         / /       | |       \ \
    node1     ...      nodeN      node1      ...      nodeM      node1      ...       nodeQ      node1      ...       nodeP
#+end_src

[07:56:13; 11.12.2025]: Makefile created.

[08:05:11; 11.12.2025]: I need to figure out how to use the platform
before trying to create one...

[17:22:18; 11.12.2025]: Lucas send me the wrong link to the proxy
apps, they are now working correctly, next step is understand how the
platform working and then trying to create mine. I stopped to search
about it in the morning because I point my focus to the LPPD table and
studying to a exam.

** 2025-12-15: Configured Proxy Apps and started creating the PCAD

[14:01:48; 15.12.2025]: I will start by revisiting what I did in the
last time.

[14:03:27; 15.12.2025]: As Lucas said: "Acho que tu podes te focar em
criar apenas uma ou duas partições. Pode ser as poti, as tupi, as cei,
e até as dracos somente." I will focus on the partitions with a lot of machines

[14:04:52; 15.12.2025]: Applications that Arthur also used: *Lulesh*,
*coMd* and *minivite*

[14:18:24; 15.12.2025]: The file
=[[file:SMPI-proxy-apps/bin/Coral_Lulesh.sh]]= can be used to compile
and run the Lulesh application. To run it manually after compiled, you
can run:

#+begin_src shell :results output :exports both
export OMP_NUM_THREADS=1
smpirun -np 8 -hostfile $PLATFORMDIR/cluster_hostfile.txt -platform $PLATFORMDIR/cluster_crossbar.xml --cfg=smpi/host-speed:100 ./lulesh2.0 -i 10

#+end_src

[14:37:09; 15.12.2025]: I am having some problems using the current
version of simgrid. I will reinstall in the default dir that I install
the libraries. Maybe I will install with spack.

[14:47:32; 15.12.2025]: I get it to work, i just need to specify the
SIMGRID_PATH env var when compiling the applications.


After compiling the Lulesh again with:
#+begin_src shell :results output :exports both
export SIMGRID_PATH=/opt/simgrid/
export WORKSPACE=$(pwd)
 ./bin/Coral_Lulesh.sh
#+end_src

I executed:
#+begin_src shell :results output :exports both
/opt/simgrid/bin/smpirun -np 4 -hostfile hostfile.txt -platform ./libgriffon_platform.so --cfg=smpi/host-speed:100f ./SMPI-proxy-apps/Benchmarks/Coral/Lulesh/lulesh2.0 -i 10
#+end_src
And everything worked! :)

(this was the output)
#+begin_src txt
[0.000000] [xbt_cfg/INFO] Configuration change: Set 'smpi/privatization' to 'ON'
[0.000000] [xbt_cfg/INFO] Configuration change: Set 'smpi/np' to '8'
[0.000000] [xbt_cfg/INFO] Configuration change: Set 'smpi/hostfile' to 'hostfile.txt'
[0.000000] [xbt_cfg/INFO] Configuration change: Set 'precision/timing' to '1e-9'
[0.000000] [xbt_cfg/INFO] Configuration change: Set 'network/model' to 'SMPI'
[0.000000] [xbt_cfg/INFO] Configuration change: Set 'smpi/host-speed' to '100f'
[0.000000] [xbt_cfg/INFO] Configuration change: Set 'smpi/tmpdir' to '/tmp'
[0.000000] [smpi/INFO] You requested to use 8 ranks, but there is only 4 processes in your hostfile...
Running problem size 30^3 per domain until completion
Num processors: 8
Num threads: 1
Total number of elements: 216000

To run other sizes, use -s <integer>.
To run a fixed number of iterations, use -i <integer>.
To run a more or less balanced region set, use -b <integer>.
To change the relative costs of regions, use -c <integer>.
To print out progress, use -p
To write an output file for VisIt, use -v
See help (-h) for more options

Run completed:
   Problem size        =  30
   MPI tasks           =  8
   Iteration count     =  10
   Final Origin Energy = 5.609011e+07
   Testing Plane 0 of Energy Array on rank 0:
        MaxAbsDiff   = 1.164153e-10
        TotalAbsDiff = 1.233715e-10
        MaxRelDiff   = 7.751076e-14


Elapsed time         =       0.07 (s)
Grind time (us/z/c)  = 0.25094378 (per dom)  (0.031367973 overall)
FOM                  =   31879.65 (z/s)
#+end_src

** 2025-12-17: Finished the pcad base?

[12:39:17; 17.12.2025]: Today and yesterday I spend the day trying to
create a functional (at least executable) platform. Now I need to
learn how to verify if it is correct.

[17:52:33; 17.12.2025]: Lucas send me the template from simgrid to
follow. I will also use nix for the reproducibility.

** 2025-12-22: Nix and cmake working

[17:09:11; 22.12.2025]: The Nix is working! There is also a cmake file
to create the lib! I can run a application with:

#+begin_src shell :results output :exports both
smpirun -np 8 -hostfile hosts.txt -platform ./result/lib/libpcad.so --cfg=smpi/host-speed:100f ./SMPI-proxy-apps/Benchmarks/Coral/Lulesh/lulesh2.0 -i 10
#+end_src

[17:14:09; 22.12.2025]: I think I can generalize the rack creation and
enable a scalatable creation using vectors. Each position is a
partition configuration (name, speed, bw and lat) of the host.


[17:19:15; 22.12.2025]: Created a script using the "amigo" to verify
the topology: =verify-platform.cpp=. The section about latency is not
important by now since it is hardcoded with the random value, but the
connections are

Compile the program:
#+begin_src shell :results output :exports both
g++ verify-platform.cpp create-pcad.cpp -o verify_platform `pkg-config --cflags --libs simgrid`
#+end_src

Convert topology.dot to png.
#+begin_src shell :results output :exports both
dot -Tpng topology.dot -o topology.png
#+end_src

** 2025-12-24: More generic and abstract creation of platform

[14:11:07; 24.12.2025]: I make it easier to create a rack by using a
partition struct and a create_rack function. As we are modeling just
two racks, and don't need to automatically link the racks, but if the
number of racks grows, it is possible to create and link the racks
automatically using two nested FORs.

[14:12:57; 24.12.2025]: I will spend the nexts days reading about the
platform calibration since it is holiday season. After the holidays I
will reach Lucas.

[14:15:14; 24.12.2025]: I think that it is possible to create a script
to automatically create the PCAD with the correct values if I could
get the information easily.

[19:04:02; 24.12.2025]: I am reading the files in the
platform_calibration project. Since everything looks very automatized,
I will try to create a workflow to generate the full calibration for
the whole pcad (if possible, need further reading).
