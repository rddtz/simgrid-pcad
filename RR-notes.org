#+STARTUP: content
#+STARTUP: overview
#+STARTUP: indent
#+TITLE: Notes on implementing the PCAD Digital Twin with SimGrid.
#+AUTHOR: Rayan Raddatz de Matos




* TODOS

** IN-PROGRESS ERAD
DEADLINE: <2026-02-25 Wed>
- State "IN-PROGRESS" from "TODO"       [2026-01-27 Tue 22:03]
Não sei se tem conteúdo suficiente mas veremos o que sai daqui.

** IN-PROGRESS [#A] Set the link and hosts speeds
DEADLINE: <2026-02-01 Sun>
- State "IN-PROGRESS" from "DONE"       [2026-01-28 Wed 22:11]
See how to get this information

[22:03:09; 27.01.2026]: I am searching about this, I will probably try
to use hpl to find the host speed, maybe a experiment with iperf3 to
find about the network?

[22:10:45; 28.01.2026]: This week I want to get the speeds done. If i
didn't manage to use hpl tomorrow I will find another way to get it.

[20:11:35; 04.02.2026]: I get the host time, but there is a high
variance for some hosts, so I will get more runs...

[20:12:10; 04.02.2026]: I will also focus in the network and on this
repo: https://framagit.org/simgrid/platform-calibration/-/tree/master/src/calibration?ref_type=heads


** TODO Validate by seeing the difference between real application


* Idea
The idea is to create a "replica" of the PCAD in [[https://simgrid.org/doc/latest/index.html][SimGrid]] using the C++ interface

* Code
** Makefile
#+begin_src makefile :tangle Makefile
CPPC=g++
CPPFLAGS=-shared -Wall -Werror -fPIC
LIBS=simgrid

.PHONY: clean platform

export PKG_CONFIG_PATH := /opt/simgrid/lib/pkgconfig:$(PKG_CONFIG_PATH) # export installation path to simgrid

pcad:
	g++ -shared -fPIC -o pcad.so create-pcad.cpp `pkg-config --cflags --libs $(LIBS)`

base:
	g++ -shared -fPIC -o libgriffon_platform.so base.cpp `pkg-config --cflags --libs $(LIBS)`

clean:
	rm -f *.so
#+end_src

** Base example (from simgrid docs)
#+begin_src C++ :tangle base.cpp :results output :exports both :main no
/* Copyright (c) 2006-2025. The SimGrid Team. All rights reserved.          */

/* This program is free software; you can redistribute it and/or modify it
 * under the terms of the license (GNU LGPL) which comes with this package. */

#include <numeric>
#include <simgrid/s4u.hpp>
namespace sg4 = simgrid::s4u;

/**
 * @brief Create a new cabinet
 *
 * This function creates the cabinet, adding the hosts and links properly.
 * See figure below for more details of each cabinet
 *
 * @param root Root netzone
 * @param name Cabinet name
 * @param radicals IDs of nodes inside the cabinet
 * @return netzone the created netzone
 */
static sg4::NetZone* create_cabinet(sg4::NetZone* root, const std::string& name, const std::vector<int>& radicals)
{
  auto* cluster      = root->add_netzone_star(name);
  std::string prefix = "griffon-";
  std::string suffix = ".nancy.grid5000.fr";

  /* create the backbone link */
  const sg4::Link* l_bb = cluster->add_link("backbone-" + name, "1.25GBps");
  sg4::LinkInRoute backbone(l_bb);

  /* create all hosts and connect them to outside world */
  for (const auto& id : radicals) {
    std::string hostname = prefix + std::to_string(id) + suffix;
    /* create host */
    const sg4::Host* host = cluster->add_host(hostname, "286.087kf");
    /* create UP/DOWN link */
    const sg4::Link* link = cluster->add_split_duplex_link(hostname, "125MBps")->set_latency("24us");

    /* add link and backbone for communications from the host */
    cluster->add_route(host, nullptr, {{link, sg4::LinkInRoute::Direction::UP}, backbone}, true);
  }

  /* create gateway */

  cluster->set_gateway(cluster->add_router(prefix + name + "-router" + suffix));

  cluster->seal();
  return cluster;
}

/** @brief Programmatic version of griffon.xml */
extern "C" void load_platform(sg4::Engine& e);
void load_platform(sg4::Engine& e)
{
  /**
   * C++ version of griffon.xml
   * Old Grid5000 cluster (not available anymore): 3 cabinets containing homogeneous nodes connected through a backbone
   *                                  1.25GBps shared link
   *                          ___________________________________
   *          1              /                |                  \
   *                        /                 |                   \
   *                       /                  |                    \
   *     ________________ /             ______|__________           \_________________
   *     |               |              |               |            |               |
   *     | cab1 router   |              | cab2 router   |            | cab3 router   |
   *     |_______________|              |_______________|            |_______________|
   *     ++++++++++++++++               ++++++++++++++++             ++++++++++++++++++  <-- 1.25 backbone
   *     / /   | |    \ \              / /    | |    \ \             / /     | |     \ \
   *    / /    | |     \ \            / /     | |     \ \           / /      | |      \ \ <-- 125Mbps links
   *   / /     | |      \ \          / /      | |      \ \         / /       | |       \ \
   * host1     ...      hostN      host1      ...      hostM      host1      ...       hostQ
   */

  auto* root = e.get_netzone_root()->add_netzone_star("AS_griffon");

  /* create top link */
  const sg4::Link* l_bb = root->add_link("backbone", "1.25GBps")->set_latency("24us")->seal();
  sg4::LinkInRoute backbone{l_bb};

  /* create cabinet1 */
  std::vector<int> rad(32);
  std::iota(rad.begin(), rad.end(), 1); // 1-29,58,59,60
  rad[rad.size() - 1]  = 60;
  rad[rad.size() - 2]  = 59;
  rad[rad.size() - 3]  = 58;
  const sg4::NetZone* cab_zone = create_cabinet(root, "cabinet1", rad);
  root->add_route(cab_zone, nullptr, {backbone});

  /* create cabinet2 */
  rad.resize(28);
  std::iota(rad.begin(), rad.end(), 30); // 30-57
  cab_zone = create_cabinet(root, "cabinet2", rad);
  root->add_route(cab_zone, nullptr, {backbone});

  /* create cabinet3 */
  rad.resize(32);
  std::iota(rad.begin(), rad.end(), 61); // 61-92
  cab_zone = create_cabinet(root, "cabinet3", rad);
  root->add_route(cab_zone, nullptr, {backbone});

  root->seal();
}
#+end_src

** Create PCAD
:PROPERTIES:
:header-args: :tangle create-pcad.cpp :main no
:END:

This currently has rack2 with cei and draco and rack4 with tupi and poti (not
fully configurated). Based on the simgrid example.

*** Libraries and namespace
#+begin_src C++ :results output :exports both
#include <numeric>
#include <simgrid/s4u.hpp>

namespace sg4 = simgrid::s4u;
#+end_src

*** Structs
#+begin_src C++ :results output :exports both
typedef struct partition {
    std::string name;
    std::string speed;
    std::string bw;
    std::string lat;
    int count;
} partition_t;
#+end_src
*** Generic function to create one partition
#+begin_src C++ :results output :exports both

/**
 ,* @brief Create a partition with N machines
 ,*
 ,* This function creates the any partition, adding the hosts and links properly.
 ,*
 ,* @param root Root netzone
 ,* @param switch_fatpipe Switch link for the rack to model the connection
 ,* @param partition Information about the hosts in the partition
 ,*/
void create_partition(sg4::NetZone* rack,
                      sg4::Link* switch_fatpipe,
		      partition_t partition)
{
  for (int id = 1; id <= partition.count; id++) {
    std::string hostname = partition.name + std::to_string(id);

    auto* host = rack->add_host(hostname, partition.speed)->set_core_count(10)->seal();
    auto* node_cable = rack->add_link(hostname + "_cable", partition.bw)->set_latency(partition.lat)->seal();

    // Looks like StarZone automatically calculates the path to the netzone gateway when the second argument is a nullptr
    rack->add_route(host,
                    nullptr,
                    std::vector<const sg4::Link*>{node_cable, switch_fatpipe});
  }
}

#+end_src
*** Generic function to create one rack
#+begin_src C++ :results output :exports both
/**
 * @brief Create a rack with N partitions
 *
 * This function creates the a rack, adding the internal partitions linked correctly.
 *
 * @param root Root netzone
 * @param rack_name Rack name
 * @param partitions Vector with the partitions information
 */
sg4::NetZone *create_rack(sg4::NetZone *root, std::string rack_name,
			  std::string switch_capacity, std::string switch_latency,
                          std::vector<partition_t> partitions)
    {

      auto* rack_zone = root->add_netzone_star(rack_name);
      auto* rack_router = rack_zone->add_router(rack_name + "_router");
      rack_zone->set_gateway(rack_router); // rack gateaway

      // Create Fatpipe to simulat the switch
      auto* rack_switch_fatpipe = rack_zone->add_link(rack_name + "_fatpipe", switch_capacity)
	->set_latency(switch_latency)
	->set_sharing_policy(sg4::Link::SharingPolicy::FATPIPE)
	->seal();

      // Nodes partitions (nodes)
      for(const auto& partition : partitions){
	create_partition(rack_zone, rack_switch_fatpipe, partition);

      }

      rack_zone->seal();
      return rack_zone;
}
#+end_src

*** MAIN: Creating two racks with some partitions (cei, draco, poti, tupi)
#+begin_src C++ :results output :exports both

/** @brief Programmatic version of PCAD */
extern "C" void load_platform(sg4::Engine& e);
void load_platform(sg4::Engine& e)
{
  auto* root = e.get_netzone_root();

  // =-=-=-=-=-=-=-=-=-=-=-= RACK 2 =-=-=-=-=-=-=-=-=-=-=-=
  partition_t cei = {"cei", "459Gf", "1Gbps", "50us", 6};
  partition_t draco = {"draco", "228Gf", "1Gbps", "50us", 6};
  std::vector<partition_t> rack2_partitions = {cei, draco};

  sg4::NetZone *rack2_zone = create_rack(root, "rack2", "10Gbps", "100ns", rack2_partitions);

  // =-=-=-=-=-=-=-=-=-=-=-= RACK 4 =-=-=-=-=-=-=-=-=-=-=-=
  partition_t tupi = {"tupi", "465Gf", "1Gbps", "50us", 6};
  partition_t poti = {"poti", "410Gf", "1Gbps", "50us", 5};
  std::vector<partition_t> rack4_partitions = {poti, tupi};

  sg4::NetZone *rack4_zone = create_rack(root, "rack4", "10Gbps", "100ns", rack4_partitions);


  // =-=-=-=-=-=-=-=-=-=-=-= CONNECTION BETWEEN THE RACKS (switchs) =-=-=-=-=-=-=-=-=-=-=-=
  std::string  inter_switch_bw = "10Gbps";
  std::string inter_switch_lat = "50us";

  auto* rack_link = root->add_link("r2_to_r4_cable", inter_switch_bw)
    ->set_latency(inter_switch_lat)
    ->seal();

  // connect the zones
  root->add_route(rack2_zone, rack4_zone, {rack_link});

  root->seal();
}
#+end_src

* Journal

#+BEGIN: clocktable :scope subtree :maxlevel 3
#+CAPTION: Clock summary at [2026-02-09 Mon 22:04]
| Headline                                      | Time  |      |      |
|-----------------------------------------------+-------+------+------|
| *Total time*                                    | *17:46* |      |      |
|-----------------------------------------------+-------+------+------|
| Journal                                       | 17:46 |      |      |
| \_  2026-01-20: Going back to work            |       | 2:40 |      |
| \_  2026-01-21: Small search about host...    |       | 0:30 |      |
| \_  2026 Week 05 [Jan]                        |       | 8:32 |      |
| \_    2026-01-26: Small search about HPL      |       |      | 1:38 |
| \_    2026-01-27: Small GUIX config           |       |      | 1:13 |
| \_    2026-01-28: Continuing with HPL         |       |      | 2:27 |
| \_    2026-01-30: Again with HPL (it's now... |       |      | 3:14 |
| \_  2026 Week 06 [Feb]                        |       | 5:00 |      |
| \_    2026-02-04                              |       |      | 2:41 |
| \_    2026-02-05                              |       |      | 2:19 |
| \_  2026 Week 07 [Feb]                        |       | 1:04 |      |
| \_    2026-02-09                              |       |      | 1:04 |
#+END:

** 2025-11-06
[11:32:57; 06.11.2025]: I will use the base example of the site
(https://simgrid.org/doc/latest/Platform_cpp.html#example) to start.

[11:41:05; 06.11.2025]: The references will stay in a separated
directory.

#+begin_src shell :results output :exports both
ls references
#+end_src

#+RESULTS:
: smpi_article.pdf

** 2025-12-05: SimGrid Install From Source

[08:40:25; 05.12.2025]: The two important points are the creation of
the interface and also the calibration.

[08:45:38; 05.12.2025]: I will start by reading and getting used to
the platform. I also want to start using the examples to see what path
should I follow.

[09:01:00; 05.12.2025]: To calibrate or validate I must first have a
functional (even though small) cluster. I will try to start with a toy
example and scale it to create the CEI partition.

CEI HARDWARE:
| name     | partition | processor                                                        | memory     | accelerator | disk                      | motherboard       |
|----------+-----------+------------------------------------------------------------------+------------+-------------+---------------------------+-------------------|
| cei[1-6] | cei       | 2 x Intel(R) Xeon(R) Silver 4116, 2.10 GHz, 48 threads, 24 cores | 96 GB DDR4 | --          | 21.8 TB HDD, 894.3 GB SSD | Supermicro X11DPU |

They are connected by a 10G Internet Switch.

[09:14:52; 05.12.2025]: I am compiling the simgrid examples to use as
base.

[09:45:13; 05.12.2025]: I think I can modulate to create the
partitions (one function for each partition) and after joint
everything to create the PCAD.

[09:46:51; 05.12.2025]: My debian current MPI version don't have a
fully updated simgrid version. I will probably download from source then.

[10:07:06; 05.12.2025]: Since Lucas said they are shifting toward Nix,
I will probably download the Nix SimGrid Version.

[11:10:48; 05.12.2025]: I made a break to go to super market. I
installed the simgrid from source (git version 4.1.1) and installed at
/opt/simgrid. To compile with this version, i need to change the dkpg
path env variable:

#+begin_src shell :results output :exports both
export PKG_CONFIG_PATH=/opt/simgrid/lib/pkgconfig:$PKG_CONFIG_PATH
#+end_src

and then compile:

#+begin_src shell :results output :exports both
g++ -shared -fPIC -o libgriffon_platform.so base.cpp $(pkg-config --cflags --libs simgrid)
#+end_src

This will create a library to my platform.

** 2025-12-09: Arthur TCC

[10:49:45; 09.12.2025]: TCC do Arthur
[10:49:51; 09.12.2025]: Como é a comunicação no pcad?

Nó -> uma máquina (ex.: cei1)

[11:35:42; 09.12.2025]: SimGrid escala bem

** 2025-12-11: Proxy Apps Working and Topology

[07:23:42; 11.12.2025]: Arrived at the lab, today my plan is to start
designing the cei nodes. I also want to read the two articles cited in
the IC propose.

[07:30:47; 11.12.2025]: Important pages about calibration:
https://simgrid.org/doc/latest/Calibrating_the_models.html#mpi-network-calibration
https://framagit.org/simgrid/platform-calibration/

[07:33:11; 11.12.2025]: [[file:network_topology.pdf]]

If i get it correctly. the topology is as follow:


#+begin_src txt
                             ___________________________________________________________________
                            /                |                              |                   \
                           /                 |                              |                    \  <---- Switch speed connection to other racks
                          /                  |                              |                     \
        ________________ /             ______|__________            ________|________              \_________________
        |               |              |               |            |               |               |               |
        | rack 1 switch |              | rack 2 switch |            | rack 3 switch |               | rack 4 switch | <-- Fatpipe with high capacity and low latency
        |_______________|              |_______________|            |_______________|               |_______________|
        ++++++++++++++++               ++++++++++++++++             ++++++++++++++++++              ++++++++++++++++++
        / /   | |    \ \              / /    | |    \ \             / /     | |     \ \             / /     | |     \ \
       / /    | |     \ \            / /     | |     \ \           / /      | |      \ \           / /      | |      \ \ <-- Switch Speed connection between nodes
      / /     | |      \ \          / /      | |      \ \         / /       | |       \ \         / /       | |       \ \
    node1     ...      nodeN      node1      ...      nodeM      node1      ...       nodeQ      node1      ...       nodeP
#+end_src

[07:56:13; 11.12.2025]: Makefile created.

[08:05:11; 11.12.2025]: I need to figure out how to use the platform
before trying to create one...

[17:22:18; 11.12.2025]: Lucas send me the wrong link to the proxy
apps, they are now working correctly, next step is understand how the
platform working and then trying to create mine. I stopped to search
about it in the morning because I point my focus to the LPPD table and
studying to a exam.

** 2025-12-15: Configured Proxy Apps and started creating the PCAD

[14:01:48; 15.12.2025]: I will start by revisiting what I did in the
last time.

[14:03:27; 15.12.2025]: As Lucas said: "Acho que tu podes te focar em
criar apenas uma ou duas partições. Pode ser as poti, as tupi, as cei,
e até as dracos somente." I will focus on the partitions with a lot of machines

[14:04:52; 15.12.2025]: Applications that Arthur also used: *Lulesh*,
*coMd* and *minivite*

[14:18:24; 15.12.2025]: The file
=[[file:SMPI-proxy-apps/bin/Coral_Lulesh.sh]]= can be used to compile
and run the Lulesh application. To run it manually after compiled, you
can run:

#+begin_src shell :results output :exports both
export OMP_NUM_THREADS=1
smpirun -np 8 -hostfile $PLATFORMDIR/cluster_hostfile.txt -platform $PLATFORMDIR/cluster_crossbar.xml --cfg=smpi/host-speed:100 ./lulesh2.0 -i 10

#+end_src

[14:37:09; 15.12.2025]: I am having some problems using the current
version of simgrid. I will reinstall in the default dir that I install
the libraries. Maybe I will install with spack.

[14:47:32; 15.12.2025]: I get it to work, i just need to specify the
SIMGRID_PATH env var when compiling the applications.


After compiling the Lulesh again with:
#+begin_src shell :results output :exports both
export SIMGRID_PATH=/opt/simgrid/
export WORKSPACE=$(pwd)
 ./bin/Coral_Lulesh.sh
#+end_src

I executed:
#+begin_src shell :results output :exports both
/opt/simgrid/bin/smpirun -np 4 -hostfile hostfile.txt -platform ./libgriffon_platform.so --cfg=smpi/host-speed:100f ./SMPI-proxy-apps/Benchmarks/Coral/Lulesh/lulesh2.0 -i 10
#+end_src
And everything worked! :)

(this was the output)
#+begin_src txt
[0.000000] [xbt_cfg/INFO] Configuration change: Set 'smpi/privatization' to 'ON'
[0.000000] [xbt_cfg/INFO] Configuration change: Set 'smpi/np' to '8'
[0.000000] [xbt_cfg/INFO] Configuration change: Set 'smpi/hostfile' to 'hostfile.txt'
[0.000000] [xbt_cfg/INFO] Configuration change: Set 'precision/timing' to '1e-9'
[0.000000] [xbt_cfg/INFO] Configuration change: Set 'network/model' to 'SMPI'
[0.000000] [xbt_cfg/INFO] Configuration change: Set 'smpi/host-speed' to '100f'
[0.000000] [xbt_cfg/INFO] Configuration change: Set 'smpi/tmpdir' to '/tmp'
[0.000000] [smpi/INFO] You requested to use 8 ranks, but there is only 4 processes in your hostfile...
Running problem size 30^3 per domain until completion
Num processors: 8
Num threads: 1
Total number of elements: 216000

To run other sizes, use -s <integer>.
To run a fixed number of iterations, use -i <integer>.
To run a more or less balanced region set, use -b <integer>.
To change the relative costs of regions, use -c <integer>.
To print out progress, use -p
To write an output file for VisIt, use -v
See help (-h) for more options

Run completed:
   Problem size        =  30
   MPI tasks           =  8
   Iteration count     =  10
   Final Origin Energy = 5.609011e+07
   Testing Plane 0 of Energy Array on rank 0:
        MaxAbsDiff   = 1.164153e-10
        TotalAbsDiff = 1.233715e-10
        MaxRelDiff   = 7.751076e-14


Elapsed time         =       0.07 (s)
Grind time (us/z/c)  = 0.25094378 (per dom)  (0.031367973 overall)
FOM                  =   31879.65 (z/s)
#+end_src

** 2025-12-17: Finished the pcad base?

[12:39:17; 17.12.2025]: Today and yesterday I spend the day trying to
create a functional (at least executable) platform. Now I need to
learn how to verify if it is correct.

[17:52:33; 17.12.2025]: Lucas send me the template from simgrid to
follow. I will also use nix for the reproducibility.

** 2025-12-22: Nix and cmake working

[17:09:11; 22.12.2025]: The Nix is working! There is also a cmake file
to create the lib! I can run a application with:

#+begin_src shell :results output :exports both
smpirun -np 8 -hostfile hosts.txt -platform ./result/lib/libpcad.so --cfg=smpi/host-speed:100f ./SMPI-proxy-apps/Benchmarks/Coral/Lulesh/lulesh2.0 -i 10
#+end_src

[17:14:09; 22.12.2025]: I think I can generalize the rack creation and
enable a scalatable creation using vectors. Each position is a
partition configuration (name, speed, bw and lat) of the host.


[17:19:15; 22.12.2025]: Created a script using the "amigo" to verify
the topology: =verify-platform.cpp=. The section about latency is not
important by now since it is hardcoded with the random value, but the
connections are

Compile the program:
#+begin_src shell :results output :exports both
g++ verify-platform.cpp create-pcad.cpp -o verify_platform `pkg-config --cflags --libs simgrid`
#+end_src

Convert topology.dot to png.
#+begin_src shell :results output :exports both
dot -Tpng topology.dot -o topology.png
#+end_src

** 2025-12-24: More generic and abstract creation of platform

[14:11:07; 24.12.2025]: I make it easier to create a rack by using a
partition struct and a create_rack function. As we are modeling just
two racks, and don't need to automatically link the racks, but if the
number of racks grows, it is possible to create and link the racks
automatically using two nested FORs.

[14:12:57; 24.12.2025]: I will spend the nexts days reading about the
platform calibration since it is holiday season. After the holidays I
will reach Lucas.

[14:15:14; 24.12.2025]: I think that it is possible to create a script
to automatically create the PCAD with the correct values if I could
get the information easily.

[19:04:02; 24.12.2025]: I am reading the files in the
platform_calibration project. Since everything looks very automatized,
I will try to create a workflow to generate the full calibration for
the whole pcad (if possible, need further reading).

** 2026-01-20: Going back to work
:LOGBOOK:
CLOCK: [2026-01-20 Tue 18:30]--[2026-01-20 Tue 21:10] =>  2:40
:END:

[18:36:10; 20.01.2026]: After some time to establish myself for the
internship, I am going back to work. I will start to use also orgclock
to mark the working time

[18:37:25; 20.01.2026]: Irei tirar a noite para ler o TCC do Arthur
(Frontier) e o artigo da Gabriella (CO2 plugin) e também retomar e ver
o que já tinha sido feito.

[18:42:30; 20.01.2026]: Alguns nodos do PCAD tem GPU também, vale
verificar se é valida a criação (posteriormente) de diferentes hosts para esses nós,
tal como é feito no trabalho do Arthur.

[18:48:49; 20.01.2026]: Ver como testaram a conexão entre hosts nesse
artigo: https://dl.acm.org/doi/10.1145/3624062.3624203

[19:01:27; 20.01.2026]: Comparar o traços MPI de uma aplicação
original com os traços gerados pelo simgrid.

[19:21:03; 20.01.2026]: O trabalho da Gabriella foca no BatSim, um
simulador para estudos de gerenciadores de recursos.

[19:21:50; 20.01.2026]: Tentar fazer algo para a ERAD. DEADLINE: <2026-02-25 Wed>

[19:50:19; 20.01.2026]: The execution is not working :) and I didnt
save how to run the experiment, I will create a README with this info.

[19:51:35; 20.01.2026]: I really want to know more about nix since it
looks very good and powerful

[20:05:57; 20.01.2026]: Searching with the version of simgrid is not updating.

[20:19:57; 20.01.2026]: I runned =nix develop --recreate-lock-file= and
looks like it works? Maybe it was dirty by something

[20:20:51; 20.01.2026]: Yes, it worked. I need to entry in the ambient
by using the =nix develop= command

[21:03:05; 20.01.2026]: I needed to recompile the proxy apps by using
the bin in the bins folder and setting the workspace env var as my pwd.

** 2026-01-21: Small search about host speed
:LOGBOOK:
CLOCK: [2026-01-21 Wed 19:30]--[2026-01-21 Wed 20:00] =>  0:30
:END:

[19:41:00; 21.01.2026]: As I don't have that much time today, I will
just search and same somethings

[19:41:55; 21.01.2026]: Looks like I can use HPL to measure the host
speed. This give me a hyper optimized max theoretical speed, but I
think it is good enough.

[19:44:59; 21.01.2026]: I can set the core count per host in the
SimGrid, I will do it later.

[19:57:59; 21.01.2026]: It is very simple to the get the core counts,
but i dont know if it works.

[19:58:20; 21.01.2026]: I need to go now, but I will read about the
HPL and how to use it and run experiments in the PCAD using a nix package.


** 2026 Week 05 [Jan]
[22:19:44; 27.01.2026]: From now on I will use the week to index
(better visualization with the org clock)
*** 2026-01-26: Small search about HPL
:PROPERTIES:
:LOGBOOK:
CLOCK: [2026-01-26 Mon 20:16]--[2026-01-26 Mon 21:54] =>  1:38
:END:

[20:16:34; 26.01.2026]: Today was a busy (and a little disappointing)
day, but I'll do a few every day, even if it is just 30 minutes, it
still better then nothing.

[20:41:45; 26.01.2026]: HPL has a hpl.dat file that configures the
execution. Correctly configuring it looks essential for a honest
result.
https://netlib.org/benchmark/hpl/tuning.html
https://www.netlib.org/benchmark/hpl/faqs.html

N: 80 % of the total amount of memory is a good guess
Nb: The bottom line is that "good" block sizes are almost always in the [32 .. 256] interval.


[21:17:45; 26.01.2026]: I will use guix while pcad don't have nix at
the moment.

Save the channels from the experiment time
#+begin_src shell :results output :exports both
guix describe -f channels > channels.scm
#+end_src

Using channel and manifest to full reproducibility
#+begin_src shell :results output :exports both
guix time-machine -C channels.scm -- shell -m manifest.scm
#+end_src

Using the shell (=--pure= removes everything else):
#+begin_src shell :results output :exports both
guix shell --pure -m manifest.scm
#+end_src


Manifesto para o hpl:
#+begin_src shell :tangle manifest.scm :results output :exports both
(specifications->manifest
  '("hpl"
    "openmpi"
    "coreutils")) ; Adiciona ls, cp, cat, etc.
#+end_src


Code to get NB:
#+begin_src shell :results output :exports both
echo "scale=0; 0.8*sqrt($(free -b | awk '{print $3}' | sed "2q;d")/8) / 1" | bc
#+end_src

Last division by one is from here:
https://askubuntu.com/questions/217570/bc-set-number-of-digits-after-decimal-point

[21:43:33; 26.01.2026]: I need to refresh guix repo and it will take
some time. I will try to run it today if it updates before I go sleep.
\
*** 2026-01-27: Small GUIX config
:LOGBOOK:
CLOCK: [2026-01-27 Tue 21:07]--[2026-01-27 Tue 22:20] =>  1:13
:END:

[21:06:58; 27.01.2026]: I don't have much time today also, but will
try to spend some time configuring GUIX to run the hpl.

[21:07:38; 27.01.2026]: The internet here in the residence is not the
better so it is a pain to use the pcad through ssh.

[22:02:29; 27.01.2026]: HPL is running, tomorrow I will run in each
node for every partition that I modeled.

[22:06:38; 27.01.2026]: My plan is to have by the end of tomorrow a
experiment to run and find out the host speed. I need to see how to
automatize this because there is a lot of parameters to look at. But i
just need a approximation to after compare with the real application.

*** 2026-01-28: Continuing with HPL
:LOGBOOK:
CLOCK: [2026-01-28 Wed 21:58]--[2026-01-28 Wed 22:09] =>  0:11
CLOCK: [2026-01-28 Wed 17:58]--[2026-01-28 Wed 20:07] =>  2:09
CLOCK: [2026-01-28 Wed 17:40]--[2026-01-28 Wed 17:47] =>  0:07
:END:

[17:43:44; 28.01.2026]: Today I have more time then the previous days,
but there is also other tasks to do.

[17:47:19; 28.01.2026]: Pause to clean the clothes.

[17:58:43; 28.01.2026]: I am back, more 30 minutes before it ready.

[19:29:26; 28.01.2026]: I am getting some problems when running the
hpl due to the HPL.dat misconfiguration.

[20:06:31; 28.01.2026]: I don't figure out the problem with the mpirun
until now... I will pause to eat.

[21:58:45; 28.01.2026]: Coming back for one more test.

[22:05:32; 28.01.2026]: The internet is awful.. During the afternoon
is better.

[22:09:15; 28.01.2026]: I can't even connect to pcad to run the
tests... I will continue tomorrow in the afternoon

*** 2026-01-30: Again with HPL (it's now or never)
:LOGBOOK:
CLOCK: [2026-01-30 Fri 17:38]--[2026-01-30 Fri 20:52] =>  3:14
:END:

[17:38:07; 30.01.2026]: Yesterday I had to go out so I don't have the
time to work in the simgrid.

[18:05:35; 30.01.2026]: The problem seems to be with the mpirun
command, i tried:
#+begin_src shell :results output :exports both
mpirun -np 24 python3 -c "from mpi4py import MPI; print(MPI.COMM_WORLD.Get_size())"
#+end_src
and the output was all ones, meaning that the process can't connect.

[18:12:25; 30.01.2026]: This command worked:
#+begin_src shell :results output :exports both
/gnu/store/a94k93jk44j44r6hcrilk31blysmqbyj-openmpi-4.1.6/bin/mpirun -np 24 xhpl
#+end_src

[18:37:24; 30.01.2026]: I executed by get a very low Gfps of 6.7... I
will see if there is any misconfiguration in the running...

#+begin_src shell :results output :exports both
dirname $(guix gc -R $(which xhpl) | grep openmpi | head -n 1)/bin/mpirun
#+end_src

[19:35:47; 30.01.2026]: Finally I have a script to run the HPL :)))),
I will know run it in different machines

[19:39:37; 30.01.2026]: I need to export this threads to avoid racing
between process:

#+begin_src shell :results output :exports both
export OPENBLAS_NUM_THREADS=1
export OMP_NUM_THREADS=1
#+end_src

[20:32:54; 30.01.2026]: I am suffering some problems due to guix but
everything will be fine..

[20:50:52; 30.01.2026]: Finally I have the script, I will run and
tomorrow morning I will then saw the results, I can then continue to
the network calibration.

** 2026 Week 06 [Feb]
*** 2026-02-04
:LOGBOOK:
CLOCK: [2026-02-04 Wed 19:06]--[2026-02-04 Wed 21:47] =>  2:41
:END:

[19:06:22; 04.02.2026]: Full week, but got some time to come back here
and see the results, I already had a sneak peak into it on sunday but
I will see it fully now.

[19:26:44; 04.02.2026]: The results are in the hpl directory into the
subdir results, the create-csv-hpl.sh scripts creates a csv from the results
#+begin_src shell :results output :exports both
ls hpl

echo ""
echo "Results for my tests:"
cat hpl/hpl-results.csv
#+end_src

#+RESULTS:
#+begin_example
create-csv-hpl.sh
hpl-results.csv
manifest.scm
results

Results for my tests:
tupi3,1769812151,103884,64,4,6,2231.19,3.3499e+02
tupi3,1769812151,103884,128,4,6,1652.75,4.5223e+02
tupi3,1769812151,103884,256,4,6,1503.50,4.9712e+02
tupi3,1769806580,103884,64,4,6,2264.71,3.3003e+02
tupi3,1769806580,103884,128,4,6,1626.71,4.5947e+02
tupi3,1769806580,103884,256,4,6,1504.14,4.9691e+02
tupi3,1769817711,103884,64,4,6,2229.52,3.3524e+02
tupi3,1769817711,103884,128,4,6,1659.17,4.5048e+02
tupi3,1769817711,103884,256,4,6,1511.99,4.9433e+02
poti3,1769810881,89918,64,4,5,1884.08,2.5725e+02
poti3,1769810881,89918,128,4,5,1342.96,3.6091e+02
poti3,1769810881,89918,256,4,5,1138.03,4.2590e+02
poti3,1769806285,89918,64,4,5,1941.20,2.4968e+02
poti3,1769806285,89918,128,4,5,1350.52,3.5889e+02
poti3,1769806285,89918,256,4,5,1150.32,4.2135e+02
poti3,1769815398,89918,64,4,5,1894.86,2.5579e+02
poti3,1769815398,89918,128,4,5,1351.59,3.5860e+02
poti3,1769815398,89918,256,4,5,1138.89,4.2558e+02
draco2,1769802650,73467,64,4,4,1280.21,2.0650e+02
draco2,1769802650,73467,128,4,4,1254.81,2.1068e+02
draco2,1769802650,73467,256,4,4,1321.54,2.0004e+02
draco2,1769811112,73467,64,4,4,1277.81,2.0689e+02
draco2,1769811112,73467,128,4,4,1254.16,2.1079e+02
draco2,1769811112,73467,256,4,4,1322.55,1.9989e+02
draco2,1769806883,73467,64,4,4,1278.83,2.0672e+02
draco2,1769806883,73467,128,4,4,1255.01,2.1065e+02
draco2,1769806883,73467,256,4,4,1320.35,2.0022e+02
cei1,1769809681,89404,64,4,6,1091.40,4.3652e+02
cei1,1769809681,89404,128,4,6,1023.40,4.6553e+02
cei1,1769809681,89404,256,4,6,1056.45,4.5096e+02
cei1,1769802641,89404,64,4,6,1092.40,4.3612e+02
cei1,1769802641,89404,128,4,6,1024.43,4.6506e+02
cei1,1769802641,89404,256,4,6,1059.66,4.4960e+02
cei1,1769806164,89404,64,4,6,1091.68,4.3641e+02
cei1,1769806164,89404,128,4,6,1024.25,4.6514e+02
cei1,1769806164,89404,256,4,6,1058.21,4.5021e+02
#+end_example

[19:28:27; 04.02.2026]: I executed only 3 repetitions to see the
variance, I will now use R to continue:

**** Checking the results

***** Loading data
#+begin_src R :results output :session *R* :exports both
options(crayon.enabled=FALSE)
suppressMessages(library(fs))
suppressMessages(library(tidyverse))

BASE <- "./hpl"
tibble(CSV = dir_ls(BASE, regexp = "csv$", recurse=TRUE)) |>
  mutate(DATA = map(CSV, read_csv, show_col_types=FALSE, progress=FALSE)) |>
  unnest(DATA) |>
  select(-CSV) -> df


df |> print(n=36)
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 36 × 8
   Machine     Run_ID      N    NB     P     Q  Time GFlops
   <chr>        <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl>  <dbl>
 1 tupi3   1769812151 103884    64     4     6 2231.   335.
 2 tupi3   1769812151 103884   128     4     6 1653.   452.
 3 tupi3   1769812151 103884   256     4     6 1504.   497.
 4 tupi3   1769806580 103884    64     4     6 2265.   330.
 5 tupi3   1769806580 103884   128     4     6 1627.   459.
 6 tupi3   1769806580 103884   256     4     6 1504.   497.
 7 tupi3   1769817711 103884    64     4     6 2230.   335.
 8 tupi3   1769817711 103884   128     4     6 1659.   450.
 9 tupi3   1769817711 103884   256     4     6 1512.   494.
10 poti3   1769810881  89918    64     4     5 1884.   257.
11 poti3   1769810881  89918   128     4     5 1343.   361.
12 poti3   1769810881  89918   256     4     5 1138.   426.
13 poti3   1769806285  89918    64     4     5 1941.   250.
14 poti3   1769806285  89918   128     4     5 1351.   359.
15 poti3   1769806285  89918   256     4     5 1150.   421.
16 poti3   1769815398  89918    64     4     5 1895.   256.
17 poti3   1769815398  89918   128     4     5 1352.   359.
18 poti3   1769815398  89918   256     4     5 1139.   426.
19 draco2  1769802650  73467    64     4     4 1280.   206.
20 draco2  1769802650  73467   128     4     4 1255.   211.
21 draco2  1769802650  73467   256     4     4 1322.   200.
22 draco2  1769811112  73467    64     4     4 1278.   207.
23 draco2  1769811112  73467   128     4     4 1254.   211.
24 draco2  1769811112  73467   256     4     4 1323.   200.
25 draco2  1769806883  73467    64     4     4 1279.   207.
26 draco2  1769806883  73467   128     4     4 1255.   211.
27 draco2  1769806883  73467   256     4     4 1320.   200.
28 cei1    1769809681  89404    64     4     6 1091.   437.
29 cei1    1769809681  89404   128     4     6 1023.   466.
30 cei1    1769809681  89404   256     4     6 1056.   451.
31 cei1    1769802641  89404    64     4     6 1092.   436.
32 cei1    1769802641  89404   128     4     6 1024.   465.
33 cei1    1769802641  89404   256     4     6 1060.   450.
34 cei1    1769806164  89404    64     4     6 1092.   436.
35 cei1    1769806164  89404   128     4     6 1024.   465.
36 cei1    1769806164  89404   256     4     6 1058.   450.
#+end_example

***** Grouping
#+begin_src R :results output :session *R* :exports both
df |> group_by(Machine, NB) |>
  summarize(
    n = n(),
    sd = sd(GFlops),
    se = (3 * sd) / sqrt(n),
    sd_time = sd(Time), # [19:49:40; 04.02.2026]: Even the time is variating a lot, maybe I need to control better
    time = sum(Time)/60,
    GF = mean(GFlops)
  )

#+end_src

#+RESULTS:
#+begin_example
`summarise()` has grouped output by 'Machine'. You can override using the `.groups` argument.
# A tibble: 12 × 8
# Groups:   Machine [4]
   Machine    NB     n     sd    se sd_time  time    GF
   <chr>   <dbl> <int>  <dbl> <dbl>   <dbl> <dbl> <dbl>
 1 cei1       64     3 0.207  0.358   0.516  54.6  436.
 2 cei1      128     3 0.251  0.436   0.550  51.2  465.
 3 cei1      256     3 0.681  1.18    1.61   52.9  450.
 4 draco2     64     3 0.196  0.339   1.20   63.9  207.
 5 draco2    128     3 0.0737 0.128   0.444  62.7  211.
 6 draco2    256     3 0.165  0.286   1.10   66.1  200.
 7 poti3      64     3 4.02   6.96   30.3    95.3  254.
 8 poti3     128     3 1.26   2.18    4.70   67.4  359.
 9 poti3     256     3 2.54   4.40    6.86   57.1  424.
10 tupi3      64     3 2.94   5.09   19.9   112.   333.
11 tupi3     128     3 4.77   8.26   17.2    82.3  454.
12 tupi3     256     3 1.55   2.69    4.73   75.3  496.
#+end_example

[19:44:15; 04.02.2026]: Poti e Tupi mostraram uma grande variancia nos
resultados entre as execuções... I will then execute more runs.


**** Continuing

[19:45:44; 04.02.2026]: I concluded that the poti and tupi machines
had a really high variance, so I will run more experiments in
general. It would be good to have a automatic workflow that identifies
if more runs are needed after the execution and runs if needed...

[20:16:22; 04.02.2026]: SimGrid emulates MPI computations, and MPI
changes its behavior depending on what is being send, so maybe I will
need to model this also.

[20:24:43; 04.02.2026]: This MPI configurations seems to be more for
when I want to run a program using the simgrid then to when creating a
platform, I will by now use my own values but keep an eye in this
information:

If I want to set a configuration to simgrid, I can do by:
#+begin_src C++ :results output :exports both
simgrid::s4u::Engine::set_config("Item:Value");
#+end_src

More information in:
https://simgrid.org/doc/latest/Configuring_SimGrid.html#options


[20:53:42; 04.02.2026]: I confess that I was a bit lost if I was
following the right way, but it seems like I am...

[20:59:52; 04.02.2026]: I will need to growth my knowledge about SSH
and learn how to use SSH Tunnels to access the notebooks through the
pcad.

[21:13:46; 04.02.2026]: I will try to go out of home more often to do
the work from UFGRS, so I can focus more...


[21:30:32; 04.02.2026]: To create the ssh tunel:
#+begin_src shell :results output :exports both
ssh -L 8888:cei2:8888 rrdmatos@pcad
#+end_src

[21:31:56; 04.02.2026]: Ok, the workflow is as follow:

First do the listed here:
https://framagit.org/simgrid/platform-calibration

Then proceed to what is listed here:
https://simgrid.org/doc/latest/Calibrating_the_models.html#mpi-network-calibration

This is what needs to be done to the things to work properly.
I will then start now! Maybe there is a way to automatize the most
part of it?

[21:36:27; 04.02.2026]: The time that I have isn't really enough, I
wanted more time to dedicate to it because it really sounds
cool. Well, I will manage it. Now I will go talk with my family, I
need to rest, tomorrow I will have time to it also.

[21:37:57; 04.02.2026]: I will just read a little more, I need to
prepare the terrain to not be so late.

[21:41:01; 04.02.2026]: I found this:
https://github.com/Ezibenroc/peanut
It looks very interesting (I just looked fast what it does), I will
look more on it tomorrow. Looks like it has a option to perform the
HPL (and I doing this manually, came on...)

[21:45:10; 04.02.2026]: Nah, this is basically only for the G5K :(

[21:46:36; 04.02.2026]: Anyway, this don't look so difficult to run. I
want to also read some papers about SimGrid.

#+begin_src shell :results output :exports both
ls references
#+end_src

#+RESULTS:
: American Institute of Aeronautics and Astronautics.pdf
: arthur-alves-tcc.pdf
: network_topology.pdf
: pitfalls.pdf
: predictions_thesis.pdf
: simgrid-batsim.pdf
: simgrid.pdf

*** 2026-02-05
:LOGBOOK:
CLOCK: [2026-02-05 Thu 19:52]--[2026-02-05 Thu 22:11] =>  2:19
:END:

[19:52:52; 05.02.2026]: Here we are, I am very tired today (busy day +
maybe sick?). I will see the results and try to run the calibration
binary to see how things goes, then in can proceed.

[19:53:54; 05.02.2026]: I will copy the code for the analytics so I
dont change what happened yesterday...

**** Checking the results

***** Loading data
#+begin_src R :results output :session *R* :exports both
options(crayon.enabled=FALSE)
suppressMessages(library(fs))
suppressMessages(library(tidyverse))

BASE <- "./hpl"
tibble(CSV = dir_ls(BASE, regexp = "csv$", recurse=TRUE)) |> print() |>
  mutate(DATA = map(CSV, read_csv, show_col_types=FALSE, progress=FALSE)) |>
  unnest(DATA) |>
  select(-CSV) -> df


df |> print(n=36)
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 1 × 1
  CSV
  <fs::path>
1 ./hpl/hpl-results.csv
# A tibble: 99 × 8
   Machine     Run_ID     N    NB     P     Q  Time GFlops
   <chr>        <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>  <dbl>
 1 draco1  1770249307 73467    64     4     4 1128.   234.
 2 draco1  1770249307 73467   128     4     4 1098.   241.
 3 draco1  1770249307 73467   256     4     4 1153.   229.
 4 draco1  1770275362 73467    64     4     4 1132.   234.
 5 draco1  1770275362 73467   128     4     4 1099.   241.
 6 draco1  1770241877 73467    64     4     4 1129.   234.
 7 draco1  1770241877 73467   128     4     4 1099.   241.
 8 draco1  1770241877 73467   256     4     4 1149.   230.
 9 draco1  1770256725 73467    64     4     4 1128.   234.
10 draco1  1770256725 73467   128     4     4 1098.   241.
11 draco1  1770256725 73467   256     4     4 1184.   223.
12 draco1  1770245585 73467    64     4     4 1134.   233.
13 draco1  1770245585 73467   128     4     4 1100.   240.
14 draco1  1770245585 73467   256     4     4 1155.   229.
15 draco1  1770260463 73467    64     4     4 1128.   234.
16 draco1  1770260463 73467   128     4     4 1098.   241.
17 draco1  1770260463 73467   256     4     4 1150.   230.
18 draco1  1770253014 73467    64     4     4 1129.   234.
19 draco1  1770253014 73467   128     4     4 1099.   241.
20 draco1  1770253014 73467   256     4     4 1155.   229.
21 draco1  1770264167 73467    64     4     4 1132.   233.
22 draco1  1770264167 73467   128     4     4 1098.   241.
23 draco1  1770264167 73467   256     4     4 1152.   230.
24 draco1  1770267876 73467    64     4     4 1129.   234.
25 draco1  1770267876 73467   128     4     4 1098.   241.
26 draco1  1770267876 73467   256     4     4 1205.   219.
27 draco1  1770271635 73467    64     4     4 1129.   234.
28 draco1  1770271635 73467   128     4     4 1098.   241.
29 draco1  1770271635 73467   256     4     4 1172.   225.
30 poti1   1770231032 89918    64     4     5 1878.   258.
31 poti1   1770231032 89918   128     4     5 1347.   360.
32 poti1   1770231032 89918   256     4     5 1137.   426.
33 poti1   1770262421 89918    64     4     5 1874.   259.
34 poti1   1770262421 89918   128     4     5 1342.   361.
35 poti1   1770262421 89918   256     4     5 1129.   429.
36 poti1   1770253445 89918    64     4     5 1870.   259.
# ℹ 63 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

***** Grouping
#+begin_src R :results output :session *R* :exports both
df |> group_by(Machine, NB) |>
  summarize(
    n = n(),
    sd = sd(GFlops),
    se = (3 * sd) / sqrt(n),
    GF = mean(GFlops),
    GFCV = sd/GF, # [19:57:04; 05.02.2026]: CV is pretty ok for most of the runs,
    #                                       but this doesn't means that the variance is so low
    time = sum(Time)/60,
    sd_time = sd(Time),
    CVTIME = sd_time/mean(time)
  )

#+end_src

#+RESULTS:
#+begin_example
`summarise()` has grouped output by 'Machine'. You can override using the `.groups` argument.
# A tibble: 12 × 10
# Groups:   Machine [4]
   Machine    NB     n     sd     se    GF     GFCV  time sd_time  CVTIME
   <chr>   <dbl> <int>  <dbl>  <dbl> <dbl>    <dbl> <dbl>   <dbl>   <dbl>
 1 cei1       64    10 31.1   29.6    392. 0.0795    204. 109.    0.536
 2 cei1      128    10  3.74   3.54   457. 0.00818   174.   8.63  0.0496
 3 cei1      256     9  1.28   1.28   444. 0.00289   161.   3.11  0.0193
 4 draco1     64    10  0.397  0.377  234. 0.00170   188.   1.93  0.0102
 5 draco1    128    10  0.114  0.108  241. 0.000472  183.   0.516 0.00282
 6 draco1    256     9  3.71   3.71   227. 0.0163    175.  19.4   0.111
 7 poti1      64     8  1.10   1.17   260. 0.00423   249.   7.89  0.0317
 8 poti1     128     8  1.25   1.33   362. 0.00345   178.   4.63  0.0259
 9 poti1     256     8  1.23   1.31   429. 0.00287   151.   3.26  0.0217
10 tupi4      64     6  0.423  0.518  309. 0.00137   242.   3.29  0.0136
11 tupi4     128     6  1.70   2.08   411. 0.00414   182.   7.51  0.0413
12 tupi4     256     5  0.219  0.294  434. 0.000505  144.   0.872 0.00608
#+end_example

[19:59:16; 05.02.2026]: cei with small block shows a really high time
variance...
the sd is more then half of the mean value...

[20:01:40; 05.02.2026]: The results are very different from the ones
from yesterday for cei, even though its the same machine...

[20:02:31; 05.02.2026]: The GF for the small block is also very
slow... What happened?

#+begin_src R :results output :session *R* :exports both
df |> filter(Machine=="cei1" & NB ==64)
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 10 × 8
   Machine     Run_ID     N    NB     P     Q  Time GFlops
   <chr>        <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>  <dbl>
 1 cei1    1770242516 89404    64     4     6 1176.   405.
 2 cei1    1770264298 89404    64     4     6 1158.   412.
 3 cei1    1770260669 89404    64     4     6 1158.   412.
 4 cei1    1770231037 89404    64     4     6 1432.   333.
 5 cei1    1770246149 89404    64     4     6 1171.   407.
 6 cei1    1770253406 89404    64     4     6 1169.   407.
 7 cei1    1770238865 89404    64     4     6 1194.   399.
 8 cei1    1770234953 89404    64     4     6 1428.   334.
 9 cei1    1770257030 89404    64     4     6 1173.   406
10 cei1    1770249774 89404    64     4     6 1176.   405.
#+end_example

[20:03:47; 05.02.2026]: Now it is possible to see, two runs with
really low results when compared to the others...

[20:05:06; 05.02.2026]: I will of course run more, and better, in
different machines, so I can get different results to model the whole
cluster (maybe the correct would be to test all nodes in the cluster?)



**** Continuing

[20:24:09; 05.02.2026]: This thing of creating a subsection and being
stuck in this forever is really annoying...

[20:28:18; 05.02.2026]: While the HPL tests run I will look for the
MPI calibration...

[20:28:35; 05.02.2026]: I saw that Otho is probably using simgrid, I
asked him about it.

[20:52:13; 05.02.2026]: I looked and Lucas has some commits in the
calibration repo, very cool!

[20:52:35; 05.02.2026]: By default the generate sizes creates 50
executions of each MPI command, I think it is a good number.

#+begin_src python :results output :exports both
import itertools
import random

random.seed(0) # [20:54:22; 05.02.2026]: I added the seed here, I think it is better to be
               #                         deterministic for the good of reproductibility :)

op = ['Recv', 'Isend', 'PingPong', 'Wtime', 'Wtime', 'Iprobe', 'Test']
sizes = [int(10**random.uniform(0, 9)) for _ in range(100)]
exp = list(itertools.product(op, sizes))
exp *= 50
random.shuffle(exp)

# print('operation, size') [20:55:17; 05.02.2026]: Also removed the header
for op, size in exp:
    print('%s, %d' % (op, size))
#+end_src

[20:56:33; 05.02.2026]: I will probably need to nodes two nodes for
the calibration. I will create a slurm for the calibration and let it
run today.


#+begin_src shell :tangle slurm/mpi-calibration.slurm :results output :exports both
#!/bin/bash
#SBATCH --job-name=Network_Calibration_SIMGRID
#partition will be defined by the command line call of sbatch
#SBATCH --nodes=2
#SBATCH --time=24:00:00
#SBATCH --output=%N_%x_%j.out
#SBATCH --error=%N_%x_%j.err

date +%D-%T 2>&1

set -euo pipefail

MACHINEFILE="nodes.$SLURM_JOB_ID"
srun -l hostname | sort -n | awk '{print $2}' > $MACHINEFILE

HOST_IDS=$(paste -sd '-' $MACHINEFILE)

DIR="calibration-$HOST_IDS-`date +%d-%m-%s`-$SLURM_JOB_ID"
mkdir $DIR

EXP_FILE="${DIR}/exp_sizes_${SLURM_JOB_ID}.csv"

make
python3 generate_size_file.py > $EXP_FILE

mpirun -np 2 -machinefile $MACHINEFILE ./calibrate -d $DIR -m 0 -M 1000000000 -p "exp-$SLURM_JOB_ID" -s $EXP_FILE

date +%D-%T 2>&1
#+end_src

[21:25:18; 05.02.2026]: Talked with Otho about and get some insights,
It would be interesting to take a look at the StarPU mechanisms for
simgrid, maybe we will make a meeting someday to talk about. I can use
the StarPU to validation of the digital twin...

[21:27:42; 05.02.2026]: Run 5 times the calibration script, the file
has already 50 replications of each combination of operation and size,
a total of =100 x 2 x 50 x 5 = 500000= experiments.

[21:29:26; 05.02.2026]: Otho send me this link, very interesting, will
take a time to read it:
https://files.inria.fr/starpu/doc/starpu.pdf#chapter.52

[21:36:40; 05.02.2026]: Maybe it will be interesting to compare the
results from a manual calibration (with all the tools I am using) with
the StarPU calibration... I need to see how to run the StarPU programs
in simgrid without using the official support.

[21:47:30; 05.02.2026]: They removed the -n option from the
calibration, the replication is all when creating the exp now, it ok,
So it will be just 10000 executions...

[22:11:06; 05.02.2026]: I sended the execution of the slurms and will
know talk with my family.

** 2026 Week 07 [Feb]
*** 2026-02-09
:LOGBOOK:
CLOCK: [2026-02-09 Mon 21:00]--[2026-02-09 Mon 22:04] =>  1:04
:END:

[21:10:37; 09.02.2026]: Seeing the results of last week experiments.

[21:16:27; 09.02.2026]: I have done more experiments regarding the
GFlops and network calibration, I run the HPL in different nodes of
the same partition, the results should be similar.


**** Checking the results

***** Loading data
#+begin_src R :results output :session *R* :exports both
options(crayon.enabled=FALSE)
suppressMessages(library(fs))
suppressMessages(library(tidyverse))

BASE <- "./hpl"
tibble(CSV = dir_ls(BASE, regexp = "csv$", recurse=TRUE)) |> print() |>
  mutate(DATA = map(CSV, read_csv, show_col_types=FALSE, progress=FALSE)) |>
  unnest(DATA) |>
  select(-CSV) -> df


df |> print(n=36)
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 1 × 1
  CSV
  <fs::path>
1 ./hpl/hpl-results.csv
# A tibble: 240 × 8
   Machine     Run_ID      N    NB     P     Q  Time GFlops
   <chr>        <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl>  <dbl>
 1 cei1    1770349513  89404    64     4     6 1091.   437.
 2 cei1    1770349513  89404   128     4     6 1026.   464.
 3 cei1    1770349513  89404   256     4     6 1066.   447.
 4 cei1    1770324738  89404    64     4     6 1099.   433.
 5 cei1    1770324738  89404   128     4     6 1033.   461.
 6 cei1    1770324738  89404   256     4     6 1069.   445.
 7 cei1    1770345983  89404    64     4     6 1093.   436.
 8 cei1    1770345983  89404   128     4     6 1026.   464.
 9 cei1    1770345983  89404   256     4     6 1068.   446.
10 cei1    1770342451  89404    64     4     6 1092.   436.
11 cei1    1770342451  89404   128     4     6 1027.   464.
12 cei1    1770342451  89404   256     4     6 1068.   446.
13 cei1    1770338920  89404    64     4     6 1091.   437.
14 cei1    1770338920  89404   128     4     6 1029.   463
15 cei1    1770338920  89404   256     4     6 1068.   446.
16 cei1    1770317538  89404    64     4     6 1146.   416.
17 cei1    1770317538  89404   128     4     6 1035.   461.
18 cei1    1770317538  89404   256     4     6 1071.   445.
19 cei1    1770335381  89404    64     4     6 1092.   436.
20 cei1    1770335381  89404   128     4     6 1029.   463.
21 cei1    1770335381  89404   256     4     6 1071.   445.
22 cei1    1770331831  89404    64     4     6 1092.   436.
23 cei1    1770331831  89404   128     4     6 1030.   463.
24 cei1    1770331831  89404   256     4     6 1071.   445.
25 cei1    1770321134  89404    64     4     6 1154.   413.
26 cei1    1770321134  89404   128     4     6 1033.   461.
27 cei1    1770321134  89404   256     4     6 1072.   444.
28 cei1    1770328283  89404    64     4     6 1095.   435
29 cei1    1770328283  89404   128     4     6 1030.   462.
30 cei1    1770328283  89404   256     4     6 1071.   445.
31 tupi3   1770361914 103884    64     4     6 2224.   336.
32 tupi3   1770361914 103884   128     4     6 1638.   456.
33 tupi3   1770361914 103884   256     4     6 1494.   500.
34 tupi3   1770328654 103884    64     4     6 2228.   335.
35 tupi3   1770328654 103884   128     4     6 1643.   455.
36 tupi3   1770328654 103884   256     4     6 1506.   496.
# ℹ 204 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

***** Grouping
#+begin_src R :results output :session *R* :exports both
df |> group_by(Machine, NB) |>
  summarize(
    n = n(),
    sd = sd(GFlops),
    se = (3 * sd) / sqrt(n),
    GF = mean(GFlops),
    GFCV = sd/GF, # [19:57:04; 05.02.2026]: CV is pretty ok for most of the runs,
    #                                       but this doesn't means that the variance is so low
    time = sum(Time)/60,
    sd_time = sd(Time),
    CVTIME = sd_time/mean(time)
  ) |> print(n=100z)

#+end_src

#+RESULTS:
#+begin_example
`summarise()` has grouped output by 'Machine'. You can override using the `.groups` argument.
# A tibble: 24 × 10
# Groups:   Machine [8]
   Machine    NB     n    sd    se    GF     GFCV  time sd_time  CVTIME
   <chr>   <dbl> <int> <dbl> <dbl> <dbl>    <dbl> <dbl>   <dbl>   <dbl>
 1 cei1       64    10 9.16  8.69   432. 0.0212    184.  24.2   0.131
 2 cei1      128    10 1.35  1.28   463. 0.00291   172.   3.00  0.0175
 3 cei1      256    10 0.863 0.819  445. 0.00194   178.   2.07  0.0116
 4 cei4       64    10 2.02  1.92   371. 0.00545   214.   6.99  0.0327
 5 cei4      128    10 0.521 0.494  456. 0.00114   174.   1.20  0.00687
 6 cei4      256    10 0.282 0.267  443. 0.000635  179.   0.682 0.00381
 7 draco1     64    10 0.259 0.246  234. 0.00111   188.   1.25  0.00663
 8 draco1    128    10 0.192 0.182  241. 0.000797  183.   0.879 0.00480
 9 draco1    256    10 1.53  1.46   229. 0.00670   192.   7.79  0.0405
10 draco2     64    10 0.346 0.329  207. 0.00168   213.   2.14  0.0100
11 draco2    128    10 0.126 0.119  211. 0.000597  209.   0.744 0.00356
12 draco2    256    10 1.14  1.08   200. 0.00567   220.   7.56  0.0344
13 poti1      64    10 0.409 0.388  259. 0.00158   312.   2.96  0.00947
14 poti1     128    10 1.04  0.984  361. 0.00287   224.   3.86  0.0172
15 poti1     256    10 0.610 0.578  428. 0.00142   189.   1.61  0.00854
16 poti2      64    10 0.569 0.540  239. 0.00238   338.   4.82  0.0143
17 poti2     128    10 1.02  0.965  334. 0.00305   242.   4.44  0.0184
18 poti2     256    10 0.596 0.566  381. 0.00157   212.   1.99  0.00940
19 tupi3      64    10 0.933 0.885  335. 0.00279   372.   6.22  0.0167
20 tupi3     128    10 2.44  2.31   454. 0.00537   274.   8.87  0.0324
21 tupi3     256    10 1.38  1.31   499. 0.00278   250.   4.17  0.0167
22 tupi4      64    10 0.340 0.323  310. 0.00110   401.   2.63  0.00656
23 tupi4     128    10 0.830 0.787  413. 0.00201   302.   3.64  0.0121
24 tupi4     256    10 0.241 0.229  435. 0.000555  287.   0.957 0.00334
#+end_example

**** Continuing

[21:20:32; 09.02.2026]: I thinked about the possibility to run the HPL
in the role cluster, as the idea is to extrapolate, I think that
doesn't make sense to hard code the cluster velocity.

[21:22:13; 09.02.2026]: I have know the results of the one that run
faster, I think I will just run it several times to have a faithful
result, I think the ambient is fully isolated by using the guix pure
flag.

[21:27:06; 09.02.2026]: The internet is awful, I can't connect to the
pcad...

**** Checking the results for all the runs together (1, 2 and 3)
***** Loading data
#+begin_src R :results output :session *R* :exports both
options(crayon.enabled=FALSE)
suppressMessages(library(fs))
suppressMessages(library(tidyverse))

BASE <- "./hpl"
tibble(CSV = dir_ls(BASE, regexp = "csv$", recurse=TRUE)) |> print() |>
  mutate(DATA = map(CSV, read_csv, show_col_types=FALSE, progress=FALSE)) |>
  unnest(DATA) |>
  select(-CSV) -> df


df |> print(n=36)
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 4 × 1
  CSV
  <fs::path>
1 ./hpl/hpl-results.csv
2 ./hpl/results/hpl-results.csv
3 ./hpl/run-1/hpl-results.csv
4 ./hpl/run-2/hpl-results.csv
# A tibble: 615 × 8
   Machine     Run_ID      N    NB     P     Q  Time GFlops
   <chr>        <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl>  <dbl>
 1 cei1    1770349513  89404    64     4     6 1091.   437.
 2 cei1    1770349513  89404   128     4     6 1026.   464.
 3 cei1    1770349513  89404   256     4     6 1066.   447.
 4 cei1    1770324738  89404    64     4     6 1099.   433.
 5 cei1    1770324738  89404   128     4     6 1033.   461.
 6 cei1    1770324738  89404   256     4     6 1069.   445.
 7 cei1    1770345983  89404    64     4     6 1093.   436.
 8 cei1    1770345983  89404   128     4     6 1026.   464.
 9 cei1    1770345983  89404   256     4     6 1068.   446.
10 cei1    1770342451  89404    64     4     6 1092.   436.
11 cei1    1770342451  89404   128     4     6 1027.   464.
12 cei1    1770342451  89404   256     4     6 1068.   446.
13 cei1    1770338920  89404    64     4     6 1091.   437.
14 cei1    1770338920  89404   128     4     6 1029.   463
15 cei1    1770338920  89404   256     4     6 1068.   446.
16 cei1    1770317538  89404    64     4     6 1146.   416.
17 cei1    1770317538  89404   128     4     6 1035.   461.
18 cei1    1770317538  89404   256     4     6 1071.   445.
19 cei1    1770335381  89404    64     4     6 1092.   436.
20 cei1    1770335381  89404   128     4     6 1029.   463.
21 cei1    1770335381  89404   256     4     6 1071.   445.
22 cei1    1770331831  89404    64     4     6 1092.   436.
23 cei1    1770331831  89404   128     4     6 1030.   463.
24 cei1    1770331831  89404   256     4     6 1071.   445.
25 cei1    1770321134  89404    64     4     6 1154.   413.
26 cei1    1770321134  89404   128     4     6 1033.   461.
27 cei1    1770321134  89404   256     4     6 1072.   444.
28 cei1    1770328283  89404    64     4     6 1095.   435
29 cei1    1770328283  89404   128     4     6 1030.   462.
30 cei1    1770328283  89404   256     4     6 1071.   445.
31 tupi3   1770361914 103884    64     4     6 2224.   336.
32 tupi3   1770361914 103884   128     4     6 1638.   456.
33 tupi3   1770361914 103884   256     4     6 1494.   500.
34 tupi3   1770328654 103884    64     4     6 2228.   335.
35 tupi3   1770328654 103884   128     4     6 1643.   455.
36 tupi3   1770328654 103884   256     4     6 1506.   496.
# ℹ 579 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

***** Grouping
#+begin_src R :results output :session *R* :exports both
df |> mutate(Machine = gsub("[0-9]", "", Machine)) |> #[20:38:07; 11.02.2026]: I am reusing this code to see the results for all exps
  group_by(Machine, NB) |>
  summarize(
    n = n(),
    sd = sd(GFlops),
    se = (3 * sd) / sqrt(n),
    GF = mean(GFlops),
    GFCV = sd/GF, # [19:57:04; 05.02.2026]: CV is pretty ok for most of the runs,
    #                                       but this doesn't means that the variance is so low
    time = sum(Time)/60,
    sd_time = sd(Time),
    CVTIME = sd_time/mean(time)
  ) |> print(n=100)

#+end_src

#+RESULTS:
#+begin_example
`summarise()` has grouped output by 'Machine'. You can override using the `.groups` argument.
# A tibble: 12 × 10
# Groups:   Machine [4]
   Machine    NB     n    sd     se    GF    GFCV  time sd_time  CVTIME
   <chr>   <dbl> <int> <dbl>  <dbl> <dbl>   <dbl> <dbl>   <dbl>   <dbl>
 1 cei        64    53 31.4  12.9    402. 0.0782  1055.   96.0  0.0911
 2 cei       128    53  3.93  1.62   459. 0.00856  917.    8.90 0.00971
 3 cei       256    52  1.87  0.779  445. 0.00421  929.    4.49 0.00483
 4 draco      64    53 13.8   5.67   222. 0.0620  1055.   75.3  0.0713
 5 draco     128    53 15.0   6.17   228. 0.0658  1030.   78.1  0.0758
 6 draco     256    52 14.2   5.92   216. 0.0659  1066.   82.2  0.0771
 7 poti       64    51  9.81  4.12   251. 0.0391  1644.   76.8  0.0467
 8 poti      128    51 13.5   5.69   350. 0.0387  1177.   54.5  0.0463
 9 poti      256    51 23.5   9.86   410. 0.0573  1009.   69.8  0.0692
10 tupi       64    49 12.5   5.36   322. 0.0389  1900.   89.8  0.0472
11 tupi      128    49 21.2   9.11   432. 0.0492  1416.   84.6  0.0597
12 tupi      256    48 32.4  14.0    465. 0.0696  1291.  112.   0.0863
#+end_example

[21:31:50; 09.02.2026]: This full results don't show me a clear path,
should I use the best machine on the cluster or the worst to model?
I think that maybe the middle one, because then I am not too pessimist
neither to optimist... So I have to test each of every cluster to see
the results... OK

**** Continuing 2

[21:35:07; 09.02.2026]: I can pick a random machine or do a screening
and find the middle one... Maybe the second options is the most
correct, but I will need to stop all the cluster for a brief moment.

[21:38:13; 09.02.2026]: This should be THE FIRST thing to do, and not
just now...

[21:40:04; 09.02.2026]: I need to see also the result of the network calibration.

[21:42:23; 09.02.2026]: I take some time to read the conversation with
Lucas because I remember he talking about something important: Use
this proxy-apps and compare with the real platform:
=Lulesh, coMd, minivite=.

[21:45:59; 09.02.2026]: After use the StarPU and Cameleon, the thing
that i talked about with Otho.

[22:04:03; 09.02.2026]: direnv is not working and Julia is calling, I
will go by now...

*** 2026-02-11:
:LOGBOOK:
CLOCK: [2026-02-11 Wed 20:50]--[2026-02-11 Wed 22:10] =>  1:20
:END:

**** Checking the results for run 3
***** Loading data
#+begin_src R :results output :session *R* :exports both
options(crayon.enabled=FALSE)
suppressMessages(library(fs))
suppressMessages(library(tidyverse))

BASE <- "./hpl"
tibble(CSV = dir_ls(BASE, regexp = "hpl\\/hpl.*csv$", recurse=TRUE)) |> print() |>
  mutate(DATA = map(CSV, read_csv, show_col_types=FALSE, progress=FALSE)) |>
  unnest(DATA) |>
  select(-CSV) -> df


df |> print(n=36)
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 1 × 1
  CSV
  <fs::path>
1 ./hpl/hpl-results.csv
# A tibble: 240 × 8
   Machine     Run_ID      N    NB     P     Q  Time GFlops
   <chr>        <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl>  <dbl>
 1 cei1    1770349513  89404    64     4     6 1091.   437.
 2 cei1    1770349513  89404   128     4     6 1026.   464.
 3 cei1    1770349513  89404   256     4     6 1066.   447.
 4 cei1    1770324738  89404    64     4     6 1099.   433.
 5 cei1    1770324738  89404   128     4     6 1033.   461.
 6 cei1    1770324738  89404   256     4     6 1069.   445.
 7 cei1    1770345983  89404    64     4     6 1093.   436.
 8 cei1    1770345983  89404   128     4     6 1026.   464.
 9 cei1    1770345983  89404   256     4     6 1068.   446.
10 cei1    1770342451  89404    64     4     6 1092.   436.
11 cei1    1770342451  89404   128     4     6 1027.   464.
12 cei1    1770342451  89404   256     4     6 1068.   446.
13 cei1    1770338920  89404    64     4     6 1091.   437.
14 cei1    1770338920  89404   128     4     6 1029.   463
15 cei1    1770338920  89404   256     4     6 1068.   446.
16 cei1    1770317538  89404    64     4     6 1146.   416.
17 cei1    1770317538  89404   128     4     6 1035.   461.
18 cei1    1770317538  89404   256     4     6 1071.   445.
19 cei1    1770335381  89404    64     4     6 1092.   436.
20 cei1    1770335381  89404   128     4     6 1029.   463.
21 cei1    1770335381  89404   256     4     6 1071.   445.
22 cei1    1770331831  89404    64     4     6 1092.   436.
23 cei1    1770331831  89404   128     4     6 1030.   463.
24 cei1    1770331831  89404   256     4     6 1071.   445.
25 cei1    1770321134  89404    64     4     6 1154.   413.
26 cei1    1770321134  89404   128     4     6 1033.   461.
27 cei1    1770321134  89404   256     4     6 1072.   444.
28 cei1    1770328283  89404    64     4     6 1095.   435
29 cei1    1770328283  89404   128     4     6 1030.   462.
30 cei1    1770328283  89404   256     4     6 1071.   445.
31 tupi3   1770361914 103884    64     4     6 2224.   336.
32 tupi3   1770361914 103884   128     4     6 1638.   456.
33 tupi3   1770361914 103884   256     4     6 1494.   500.
34 tupi3   1770328654 103884    64     4     6 2228.   335.
35 tupi3   1770328654 103884   128     4     6 1643.   455.
36 tupi3   1770328654 103884   256     4     6 1506.   496.
# ℹ 204 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_example

***** Grouping
#+begin_src R :results output :session *R* :exports both
df |> group_by(Machine, NB) |>
  summarize(
    n = n(),
    sd = sd(GFlops),
    se = (3 * sd) / sqrt(n),
    GF = mean(GFlops),
    GFCV = sd/GF,
    time = sum(Time)/60,
    sd_time = sd(Time),
    CVTIME = sd_time/mean(time)
  ) |> print(n=100)

#+end_src

#+RESULTS:
#+begin_example
`summarise()` has grouped output by 'Machine'. You can override using the `.groups` argument.
# A tibble: 24 × 10
# Groups:   Machine [8]
   Machine    NB     n    sd    se    GF     GFCV  time sd_time  CVTIME
   <chr>   <dbl> <int> <dbl> <dbl> <dbl>    <dbl> <dbl>   <dbl>   <dbl>
 1 cei1       64    10 9.16  8.69   432. 0.0212    184.  24.2   0.131
 2 cei1      128    10 1.35  1.28   463. 0.00291   172.   3.00  0.0175
 3 cei1      256    10 0.863 0.819  445. 0.00194   178.   2.07  0.0116
 4 cei4       64    10 2.02  1.92   371. 0.00545   214.   6.99  0.0327
 5 cei4      128    10 0.521 0.494  456. 0.00114   174.   1.20  0.00687
 6 cei4      256    10 0.282 0.267  443. 0.000635  179.   0.682 0.00381
 7 draco1     64    10 0.259 0.246  234. 0.00111   188.   1.25  0.00663
 8 draco1    128    10 0.192 0.182  241. 0.000797  183.   0.879 0.00480
 9 draco1    256    10 1.53  1.46   229. 0.00670   192.   7.79  0.0405
10 draco2     64    10 0.346 0.329  207. 0.00168   213.   2.14  0.0100
11 draco2    128    10 0.126 0.119  211. 0.000597  209.   0.744 0.00356
12 draco2    256    10 1.14  1.08   200. 0.00567   220.   7.56  0.0344
13 poti1      64    10 0.409 0.388  259. 0.00158   312.   2.96  0.00947
14 poti1     128    10 1.04  0.984  361. 0.00287   224.   3.86  0.0172
15 poti1     256    10 0.610 0.578  428. 0.00142   189.   1.61  0.00854
16 poti2      64    10 0.569 0.540  239. 0.00238   338.   4.82  0.0143
17 poti2     128    10 1.02  0.965  334. 0.00305   242.   4.44  0.0184
18 poti2     256    10 0.596 0.566  381. 0.00157   212.   1.99  0.00940
19 tupi3      64    10 0.933 0.885  335. 0.00279   372.   6.22  0.0167
20 tupi3     128    10 2.44  2.31   454. 0.00537   274.   8.87  0.0324
21 tupi3     256    10 1.38  1.31   499. 0.00278   250.   4.17  0.0167
22 tupi4      64    10 0.340 0.323  310. 0.00110   401.   2.63  0.00656
23 tupi4     128    10 0.830 0.787  413. 0.00201   302.   3.64  0.0121
24 tupi4     256    10 0.241 0.229  435. 0.000555  287.   0.957 0.00334
#+end_example

[20:27:20; 11.02.2026]: The results aren't that good but by the moment
I will follow with these. I have an idea of the Gflops of one of the
machines in the cluster

**** Continuing

[20:50:27; 11.02.2026]: I rerun the tupi mpi experiment because there is no need for it to be only there.

[21:17:54; 11.02.2026]: There is some problems with the poetry that i
don't know what are...

[21:47:05; 11.02.2026]: I think the problem maybe is whit my python.

[22:10:26; 11.02.2026]: I will try this later.
